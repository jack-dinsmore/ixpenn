# Description

A repository to contain the Romani group's IXPE data processed with Neural Nets (NN).

A. Lawrence Peirson is the original author of the NN software

Jack Dinsmore maintains this directory on Sherlock.

# Instructions

0. *Preparation*
    - Download all available files from the IXPE database for your observation to `/home/groups/rwr/ixpenn/data/` by running the `wget` script IXPE gives you in that directory. (Level 2 files are not necessary but since they contain the official Moments-processed data you might want them. I'm not sure if `auxil` are necessary either.)
    - Unzip the files in the `event_l1` and `hk` directories with `gunzip *`.
    - If each fits file in `event_l1` is more than 2 million counts (check this with the HEASarc `ftlist` tool) then split them into 1-2 million count chunks using `split.sh`.
    - Update `source_select.sh` with the metadata for this source. That file contains instructions on how to do this.

1. *Reconstruct the event data* Run `1init.sh` using the following command, where `YOUR_SOURCE_NAME` is replaced with the name you chose to use in `source_select.sh`. This might take an hour or so.
```
sbatch --export=SOURCE=YOUR_SOURCE_NAME 1init.sh
```
If you are only interested in doing moments processing, pass the `USE_MOM` flag using `--export=SOURCE=YOUR_SOURCE_NAME,USE_MOM` and skip to step 4.

2. *Convert the hexagonal grid to square* Run `2hex.sh` using the same command, with `1init.sh` replaced with `2hex.sh`. This may take a little under an hour.

3. *Run the NN processing* Run `3nn.sh` in the same way. This will take potentially a full day to run, both due to the complexity of the calculation and delays in scheduling nodes with the GPUs required on Sherlock.

4. *Delete unused data to save space* Run `4delete.sh` using the same format. This deletes the data generated by steps 2 and 3, and also removes all reference to the original tracks. If you want to keep the NN and hex data, only run the `python3 recon_trim.py` and `python3 hack-fits.py` lines. You should eventually run the entire `delete` script because the files are very large.

5. *Run the systematic correction codes published by the IXPE collaboration* This part of the process depends on HEASarc. Run `5correct.sh`. If you'd like to only repeat the Mom reconstruction, add the `USE_MOM` flag as in step 1.

6. *Check the logs for errors* Run `error_check.sh LOG_FILES` at any point, replacing `LOG_FILES` with the log files you'd like to check for errors. This can be done manually of course but if the logs are long it can be easy to miss the messages.

If you need to simulate the data set, `sim.sh` helps with that but you need an installation of `gpdsw`.
