# Description

A repository to contain the Romani group's IXPE data processed with Neural Nets (NN).

A. Lawrence Peirson is the original author of the NN software

Jack Dinsmore created the level1 to level2 pipeline and maintains this directory on Sherlock.

# Installation

Thanks to Peter Lindholm for helping to bug test the installation process. This software is compatible with HEASoft version 6.32.1. Below are the installation instructions for the pipeline

1. (Sherlock users skip this step) Many python modules are listed in src/mlnn.sh and src/mlixpe.sh. If you have a computing cluster, replace the lines in these files with the appropriate loading statements for your cluster. If not, pip install each module and delete the text in the files so they are blank.

2. Pip install `scikit-learn` with version 0.24.2, `multiprocess` with version 0.70.12.2, and `setuptools` with version 39.2.0. Make sure to do this in the same python environment as the one that contains the python modules you installed in step one. If you skipped step one, just run src/mlnn.sh to load the environment.

3. Install `apex` via git by running the following in your home directory
```bash
git clone https://github.com/NVIDIA/apex.git
git checkout 5ba7af18f0cdb228b00ee7110236dc7c1b23fc35
pip install -v --disable-pip-version-check --no-build-isolation --no-cache-dir ./
```
Note that `pip install apex` does not work for `apex`; the PyPI version of `apex` is an unrelated module.


# Instructions

0. *Preparation*
    - Download all available files from the IXPE database for your observation to the `data/` directory by running the `wget` script IXPE gives you in that directory. (Level 2 files are not necessary but since they contain the official Moments-processed data you might want them. I'm not sure if `auxil` are necessary either.)
    - Unzip the files in the `event_l1` and `hk` directories with `gunzip *`.
    - If each fits file in `event_l1` is more than 2 million counts (check this with the HEASarc `ftlist` tool) then split them into 1-2 million count chunks using `split.sh`. You should use "chunk" names that are distinct from the observation number or the set number, and this should be reflected in source_select.sh.
    - Update `source_select.sh` with the metadata for this source. That file contains instructions on how to do this.

1. *Reconstruct the event data* Run `1init.sh` using the following command, where `YOUR_SOURCE_NAME` is replaced with the name you chose to use in `source_select.sh`. This might take an hour or so.
```
sbatch --export=SOURCE=YOUR_SOURCE_NAME 1init.sh
```
If you are only interested in doing moments processing, pass the `USE_MOM` flag using `--export=SOURCE=YOUR_SOURCE_NAME,USE_MOM=a` and skip to step 4.

2. *Convert the hexagonal grid to square* Run `2hex.sh` using the same command, with `1init.sh` replaced with `2hex.sh`. This may take a little under an hour.

3. *Run the NN processing* Run `3nn.sh` in the same way. This will take potentially a full day to run, both due to the complexity of the calculation and delays in scheduling nodes with the GPUs required on Sherlock.

4. *Delete unused data to save space* Run `4delete.sh` using the same format. This deletes the data generated by steps 2 and 3, and also removes all reference to the original tracks. If you want to keep the NN and hex data, only run the `python3 recon_trim.py` and `python3 hack-fits.py` lines. You should eventually run the entire `delete` script because the files are very large.

5. *Run the systematic correction codes published by the IXPE collaboration* This part of the process depends on HEASarc. Run `5correct.sh`. If you'd like to only repeat the Mom reconstruction, add the `USE_MOM` flag as in step 1.

6. *Check the logs for errors* Run `error_check.sh LOG_FILES` at any point, replacing `LOG_FILES` with the log files you'd like to check for errors. This can be done manually of course but if the logs are long it can be easy to miss the messages.

7. *Undo aspect correction* (Optional) If you would like to aspect correct yourself, run 6unasp.sh

8. *Remove particle background* (Optional) If you want to apply Di Marco's background subtraction algorithm, use 7bkg.src

If you need to simulate the data set, `sim.sh` helps with that but you need an installation of `gpdsw`.
